---
  - name: set hammer credentials
    template:
      src: templates/cli_config.yml.j2
      dest: /etc/hammer/cli_config.yml
    tags: init

  - name: get organization id
    shell: "hammer --csv organization list | tail -n +2 | awk -F ',' '{print $1}'"
    register: organization_id
    changed_when: false
    tags: init

  - name: add hammer organization default
    command: "hammer defaults add --param-name organization_id --param-value {{ organization_id.stdout }}"
    tags: init

  - name: create manifest folder
    file:
      state: directory
      path: /root/manifest/
      owner: root
      group: root
    tags: init

  - name: transfer manifest
    copy:
      src: files/manifest.zip
      dest: /root/manifest/manifest.zip
    tags: init

  - name: upload manifest
    command: hammer subscription upload --file /root/manifest/manifest.zip
    tags: init


# LOCATIONS
  - name: add locations
    command: hammer location create --name "{{ item }}"
    register: locations
    failed_when: locations.rc != 0 and 'Name has already been taken' not in locations.stderr
    with_items: "{{ additional_locations }}"

# LIFECYCLE ENVIRONMENTS
  - name: get current lifecycle environments
    shell: hammer --csv lifecycle-environment list | tail -n +2 | awk -F ',' '{print $2}'
    register: current_lifecycle_environments
    changed_when: false
    tags: lifecycle_environments

  - name: create lifecycle environments
    command: hammer lifecycle-environment create --name {{ item.name }} --prior {{ item.previous }}
    when: item.name not in current_lifecycle_environments.stdout
    with_items: "{{ lifecycle_environments }}"
    ignore_errors: true
    tags: lifecycle_environments

# REPOSITORIES

  - name: enable rhel repositories
    command: >
      hammer repository-set enable 
      --product '{{ item.product }}' 
      --name '{{ item.repo }}'
      {% if item.basearch is defined %} --basearch '{{ item.basearch }}'{% endif %}
      {% if item.releasever is defined %} --releasever '{{ item.releasever }}'{% endif %}
    with_items: "{{ redhat_repositories }}"
    register: reposet_enable_result
#    ignore_errors: true
    failed_when: "'Error: repository_set not found' in reposet_enable_result.stderr or 'does not seem to be a valid repository' in reposet_enable_result.stderr or 'cannot be specified for' in  reposet_enable_result.stderr"
    tags: repositories

  - name: get current products
    shell: hammer --csv product list --custom true | tail -n +2 | awk -F ',' '{print $2}'
    register: current_products
    changed_when: false
    tags: products, repositories

  - name: create custom products 
    command: hammer product create --name '{{ item.name }}' 
    when: item.name not in current_products.stdout 
    with_items: "{{ custom_products }}" 
    tags: products, repositories

  - name: get current repositories 1
    shell: hammer --csv repository list | tail -n +2 | awk -F ',' '{print $2}' 
    register: current_repositories 
    changed_when: false 
    tags: repositories 

  - name: create custom repositories 
    command: > 
      hammer repository create  
      --content-type {{ item.1.content_type }} 
       --url {{ item.1.url }}
       --product '{{ item.0.name }}'
       --name '{{ item.1.name }}'
#       --gpg-key {{ item.1.gpg_key.split('/')[-1] }} 
    when:  item.1.name not in current_repositories.stdout 
    with_subelements: 
    - "{{ custom_products }}" 
    - repositories  
    tags: repositories 

 # - name: create gpg folder
 #   file:
 #     state: directory
 #     path: /root/gpg-keys
 #     owner: root
 #     group: root
 #   tags: repositories
 #     
 # - name: download GPG keys
 #   get_url:
 #     url: "{{ item.1.gpg_key }}"
 #     dest: "/root/gpg-keys/{{ item.1.gpg_key.split('/')[-1] }}"
 #   use_proxy: yes  
 #     validate_certs: no
 #   with_subelements:
 #   - "{{ custom_products }}"
 #   - repositories
 #   environment:
 #     http_proxy: 'http://{{ proxy_username }}:{{ proxy_password }}@{{ proxy_hostname }}:{{ proxy_port }}'
 #     https_proxy: 'http://{{ proxy_username }}:{{ proxy_password }}@{{ proxy_hostname }}:{{ proxy_port }}'

 # - name: place gpg keys
 #   copy:
 #     src: "files/{{ item.1.gpg_key }}"
 #     dest: "/root/gpg-keys/{{ item.1.gpg_key }}"
 #   with_subelements:
 #   - "{{ custom_products }}"
 #   - repositories
 #   tags: repositories

 # - name: get current GPG keys
 #   shell: hammer --csv gpg list | tail -n +2 | awk -F ',' '{print $2}'
 #   register: current_gpg_keys
 #   changed_when: false
 #   tags: repositories

 # - name: create GPG keys
 #   shell: hammer gpg create --name {{ item.1.gpg_key.split('/')[-1] }} --key /root/gpg-keys/{{ item.1.gpg_key.split('/')[-1] }}
 #   when: item.1.gpg_key.split('/')[-1] not in current_gpg_keys.stdout
 #   with_subelements:
 #   - "{{ custom_products }}"
 #   - repositories 
 #   tags: repositories

  - name: get current repositories
    shell: hammer --csv repository list | tail -n +2 | awk -F ',' '{print $2}'
    register: current_repositories
    changed_when: false
    tags: repositories


  - name: get current repository IDs
    shell: hammer --csv repository list | tail -n +2 | awk -F ',' '{print $1}'
    register: current_repository_ids
    changed_when: false
    tags: repositories


  - name: update download policy on all repositories to on_demand, this will be changed later after CV's have been created
    command: hammer repository update --download-policy on_demand --id {{ item }}
    with_items: "{{ current_repository_ids.stdout_lines }}"
    changed_when: false
    ignore_errors: true
    tags: repositories

    # this task makes sure there are no sync tasks running before starting new sync tasks
  - name: wait for sync tasks to complete
    action:
      shell hammer --csv task list --search 'label = Actions::Katello::Repository::Sync and state = running'
    register: running_sync_tasks
    until: running_sync_tasks.stdout.find("running") == -1
    delay: 60
    retries: 600
    changed_when: false
    tags: repositories, sync

  - name: sync all repositories
    command: hammer repository synchronize --async --id {{ item }}
    with_items: "{{ current_repository_ids.stdout_lines }}"
    tags: repositories, sync

    # this tasks makes sure that sync tasks are complete before continuing
  - name: wait for sync tasks to complete
    action:
      shell hammer --csv task list --search 'label = Actions::Katello::Repository::Sync and state = running'
    register: running_sync_tasks
    until: running_sync_tasks.stdout.find("running") == -1
    delay: 60
    retries: 600
    changed_when: false
    tags: repositories, sync

# CONTENT VIEWS
  - block:
    - name: get current content views 
      shell: hammer --csv content-view list --nondefault true | tail -n +2 | awk -F ',' '{print $2}'
      register: current_content_views
      changed_when: false
      tags: content_views
  
    - name: Print create_content_views
      debug:
        msg: "{{ current_content_views }}"
      tags: content_views
  
    - name: Print content_views
      debug:
        msg: "{{ content_views }}"
      tags: content_views
  
    - name: Set CV list from conf file
      set_fact:
        cv_conf_list: "[{%for cv in content_views %}'{{ cv.name }}',{% endfor %}]"
      tags: content_views
  
    - name: print CV names
      debug: 
        msg: "{{ item }}"
      with_items: "{{ cv_conf_list }}"
      tags: content_views
  
  
    - name: compare already present CVs with CVs from yaml
      debug: 
        msg: "{{ cv_conf_list | difference(current_content_views.stdout_lines) }}"
      tags: content_views
  
    - name: set CV create list
      set_fact:
        cv_create_list: "{{ cv_conf_list | difference(current_content_views.stdout_lines) }}" 
      tags: content_views
    
    - name: create content views
      command: hammer content-view create --name {{ item }}
      with_items: "{{ cv_create_list }}"
      register: create_content_views
      tags: content_views
  
  
    - name: get current content views after creation
      shell: hammer --csv content-view list --nondefault true | tail -n +2 | awk -F ',' '{print $2}'
      register: current_content_views
      changed_when: false
      tags: content_views
  
    - name: Print create_content_views
      debug:
        msg: "{{ create_content_views }}"
  
    - name: associate repositories to content views 
      command: > 
        hammer content-view add-repository 
        --name {{ item.0.name }} 
        --repository '{{ item.1.repo_name }}' 
        --product '{{ item.1.product }}'
      with_subelements:
      - "{{ content_views }}"
      - repos
      #when: create_content_views.changed and "{{ item.0.name }}" in "{{ cv_create_list }}"
      tags: content_views
  
  
    - name: get current content views
      shell: hammer --csv content-view list --nondefault true | tail -n +2 | awk -F ',' '{print $2}'
      register: current_content_views
      changed_when: false
      tags: content_views
  
    - name: publish all newly created content views
      command: hammer content-view publish --async --name "{{ item }}"
      when: cv_create_list is defined
      with_items: "{{ cv_create_list }}"
      tags: content_views, publish
  
    - name: wait for publish tasks to complete
      action:
        shell hammer --csv task list --search 'label = Actions::Katello::ContentView::Publish and state = running'
      register: running_sync_tasks
      until: running_sync_tasks.stdout.find("running") == -1
      delay: 60
      retries: 60
      changed_when: false
      tags: content_views, publish
  
    - name: get current lifecycle environments
      shell: hammer --csv lifecycle-environment list --library false | tail -n +2 | awk -F ',' '{print $2}'
      register: current_lifecycle_environments
      changed_when: false
      tags: lifecycle_environments, content_views
  
    # Will make sure they are all promoted on a complete configuration run
    #Only running -t content_views for instance wouldn't dip this
    # and it would skip the promotion tasks 
    - name: set promote_all to true
      set_fact: 
        promote_all: true 
  
    # TODO: this task could be made with --async to increase speed but currently it would break because of the read lock that is put on each CV
    - name: promote latest version of each content view to all lifecycle environments
      command: >
        hammer content-view version promote 
        --from-lifecycle-environment Library
        --to-lifecycle-environment {{ item.1 }} 
        --content-view {{ item.0.name }}
        --force
      with_subelements:
      - "{{ content_views }}"
      - lifecycle_environments
      when: promote_all == true
      tags: content_views
  
    - name: promote latest version of each content view to it's lifecycle environments
      command: >
        hammer content-view version promote 
        --from-lifecycle-environment Library
        --to-lifecycle-environment {{ item.1 }} 
        --content-view {{ item.0.name }}
        --force
      when: "cv_create_list is defined and '{{ item.0.name }}' in cv_create_list and {{ promote_all }} == false"
      with_subelements:
      - "{{ content_views }}"
      - lifecycle_environments
      tags: promote
    tags: content_views 
# ACTIVATION KEYS
  - block:
    - name: get current activation keys
      shell: hammer --csv activation-key list | tail -n +2 | awk -F ',' '{print $2}'
      register: current_activation_keys
      changed_when: false

    - name: print aks
      debug:
        msg: "ITEM 0 CV : {{ item.0.name }}, ITEM1 LE's {{ item.1 }}: AK-{{ item.0.name }}-{{ item.1 }}"
      with_subelements:
      - "{{ content_views }}"
      - lifecycle_environments

    - name: create activation keys for CV & LE combinations
      command: > 
        hammer activation-key create 
        --name AK-{{ item.0.name }}-{{ item.1 }} 
        --lifecycle-environment {{ item.1 }} 
        --content-view {{ item.0.name }}
      when: "'AK-{{ item.0.name }}-{{ item.1 }}' not in current_activation_keys.stdout_lines"
      with_subelements:
      - "{{ content_views }}"
      - lifecycle_environments 
        # eg. the nested lifecycle_environments list in Content Views
      register: create_activation_keys

    - name: set release version on activation keys 
      command: > 
        hammer activation-key update  
        --name AK-{{ item.0.name }}-{{ item.1 }}
        --release-version {{ item.0.rhel_major }}Server 
      when: create_activation_keys 
      with_subelements: 
      - "{{ content_views }}"
      - lifecycle_environments 
      tags: activation_keys 

    - name: starting
      debug: 
    - name: get current activation keys
      shell: hammer --csv activation-key list | tail -n +2 | awk -F ',' '{print $2}'
      register: current_activation_keys
      changed_when: false
    
    - debug: 
        msg: "{{ current_activation_keys }}"
    - set_fact:
        custom_product_names: "[{% for product in custom_products %}'{{ product.name }}',{% endfor %}]"
  
    - set_fact:
        cv_custom_sub_list: []
  
    - name: get list of custom products in CV
      set_fact:
        #msg: "{% if item.1.product in custom_product_names %}{{ item.1.product }}{% endif %}"
        cv_custom_sub_list: "{{ cv_custom_sub_list|default({}) + [ {'cv': item.0.name, 'product': item.1.product} ] }}"
      when: item.1.product in custom_product_names
      with_subelements:
      - "{{ content_views }}"
      - repos 

    - name: set fact ak_custom_sub_list
      set_fact:
        ak_custom_sub_list: []

    - name: set aks who should get a product based on the CV name 
      set_fact:
        #msg: "{% if item.1.product in custom_product_names %}{{ item.1.product }}{% endif %}"
        ak_custom_sub_list: "{{ ak_custom_sub_list|default({}) + [ {'ak': item.1, 'product': item.0.product} ] }}"
      when: item.0.cv in item.1
      with_nested:
      - "{{ cv_custom_sub_list }}"
      - "{{ current_activation_keys.stdout_lines }}"

    - name: print ak_custom_sub_list
      debug:
        msg: "{{ ak_custom_sub_list }}"


    - name: add_custom_subscriptions_to_keys
      shell: > 
        hammer activation-key add-subscription  
        --name '{{ item.ak }}' 
        --subscription-id $(hammer --csv subscription list --search '{{ item.product }}' | tail -n +2 | awk -F ',' '{print $1}') 
      with_items:
      - "{{ ak_custom_sub_list }}"
    tags: activation_keys
  
  - name: get current host collections
    shell: hammer --csv host-collection list | tail -n +2 | awk -F ',' '{print $2}'
    register: current_host_collections
    changed_when: false

  - name: create host collections for each lifecycle environment
    command: hammer host-collection create --name '{{ item.name }}'
    when: "'HC-{{ item.name }}' not in current_host_collections.stdout"
    with_items: "{{ lifecycle_environments }}"

  - name: create host collections for each content view
    command: hammer host-collection create --name '{{ item.name }}'
    when: "'HC-{{ item.name }}' not in current_host_collections.stdout"
    with_items: "{{ content_views }}"

  - name: create host collections for each location
    command: hammer host-collection create --name '{{ item.name }}'
    when: "'HC-{{ item.name }}' not in current_host_collections.stdout"
    with_items:
    - "{{ location }}"
    - "{{ additional_locations }}"

#  - name: get current host groups
#    shell: hammer --csv hostgroup list | tail -n +2 | awk -F ',' '{print $3}'
#    register: current_host_groups
#    changed_when: false
#
#  - name: create host groups for lifecycle environments
#    command: >
#      hammer hostgroup create
#      --organization '{{ organization }}'
#      --name 'HG-{{ item.name }}'
#      --lifecycle-environment '{{ item.name }}'
#      --environment production
#      --content-source-id 1
#      --domain-id 1
#    when: "'HG-{{ item.name }}' not in current_host_groups.stdout"
#    with_items: "{{ lifecycle_environments }}"
#
#  # TODO: This is currently hard coded to only work with RHEL7. A similar task would have to be added for RHEL 5 or 6 if it should be used.
#  # The architecture and operatingsystem name are also hard coded to x86_64 and RedHat 7.3 respectively
#  - name: create a RHEL 7 host group under each lifecycle environment
#    command: >
#      hammer hostgroup create
#      --organization '{{ organization }}'
#      --name 'RHEL7'
#      --parent 'HG-{{ item.name }}'
#      --architecture 'x86_64'
#      --operatingsystem 'RedHat 7.3'
#    when: "'HG-{{ item.name }}/RHEL7' not in current_host_groups.stdout"
#    with_items: "{{ lifecycle_environments }}"
#
#  # TODO: Same here, also hard coded to only support RHEL7
#  - name: create host groups for each profile
#    shell: >
#      hammer hostgroup create 
#      --organization '{{ organization }}'
#      --name '{{ item.1.name }}'
#      --content-view 'CV-RHEL7-{{ item.1.name }}'
#      --parent-id $(hammer --csv hostgroup list --search 'title = HG-{{ item.0.name }}/RHEL7' | tail -n +2 | awk -F ',' '{print $1}')
#    when: "'HG-{{ item.0.name }}/RHEL7/{{ item.1.name }}' not in current_host_groups.stdout"
#    register: create_profile_host_groups
#    with_nested:
#    - "{{ lifecycle_environments }}"
#    - "{{ profiles }}"
#
#  - name: set activation key for each profile host group
#    shell: >
#      hammer hostgroup set-parameter
#      --hostgroup-title 'HG-{{ item.0.name }}/RHEL7/{{ item.1.name }}'
#      --name kt_activation_keys --value 'AK-{{ item.0.name }}-RHEL7-{{ item.1.name }}'
#    when: create_profile_host_groups.changed
#    with_nested:
#    - "{{ lifecycle_environments }}"
#    - "{{ profiles }}"#


## SYNC IN THE END
  - name: "update download policy on all repositories to {{ donwload_policy }}"
    command: hammer repository update --download-policy {{ download_policy }} --id {{ item }}
    with_items: "{{ current_repository_ids.stdout_lines }}"
    changed_when: false
    ignore_errors: true
    tags: repositories

    # this task makes sure there are no sync tasks running before starting new sync tasks
  - name: get current repository IDs
    shell: hammer --csv repository list | tail -n +2 | awk -F ',' '{print $1}'
    register: current_repository_ids
    changed_when: false
    tags: final

  - name: wait for sync tasks to complete
    action:
      shell hammer --csv task list --search 'label = Actions::Katello::Repository::Sync and state = running'
    register: running_sync_tasks
    until: running_sync_tasks.stdout.find("running") == -1
    delay: 60
    retries: 600
    changed_when: false
    tags: final

  - name: sync all repositories
    command: hammer repository synchronize --async --id {{ item }}
    with_items: "{{ current_repository_ids.stdout_lines }}"
    tags: final

    # this tasks makes sure that sync tasks are complete before continuing
  - name: wait for sync tasks to complete
    action:
      shell hammer --csv task list --search 'label = Actions::Katello::Repository::Sync and state = running'
    register: running_sync_tasks
    until: running_sync_tasks.stdout.find("running") == -1
    delay: 60
    retries: 600
    changed_when: false
    tags: final

